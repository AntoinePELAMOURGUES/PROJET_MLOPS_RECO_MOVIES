{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Dataset, Reader\n",
    "from surprise.prediction_algorithms.matrix_factorization import SVD\n",
    "from surprise import accuracy\n",
    "import pandas as pd\n",
    "from surprise.model_selection import cross_validate\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_ratings(ratings_csv: str, data_dir: str = \"/home/antoine/PROJET_MLOPS_RECO_MOVIES/data/raw/silver\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Lit le fichier CSV contenant les évaluations des films.\n",
    "\n",
    "    :param ratings_csv: Nom du fichier CSV contenant les évaluations.\n",
    "    :param data_dir: Répertoire où se trouve le fichier CSV.\n",
    "    :return: DataFrame contenant les évaluations.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        filepath = os.path.join(data_dir, ratings_csv)\n",
    "        df = pd.read_csv(filepath)\n",
    "        print(\"Dataset ratings chargé\")\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Erreur: Le fichier {filepath} n'a pas été trouvé.\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def train_model(df: pd.DataFrame, n_factors: int = 150, n_epochs: int = 30, lr_all: float = 0.01, reg_all: float = 0.05) -> SVD:\n",
    "    \"\"\"Entraîne le modèle de recommandation sur les données fournies.\"\"\"\n",
    "    # Diviser les données en ensembles d'entraînement et de test\n",
    "    reader = Reader(rating_scale=(0.5, 5))\n",
    "\n",
    "    data = Dataset.load_from_df(df[['userid', 'movieid', 'rating']], reader=reader)\n",
    "\n",
    "    # Extraire le Trainset\n",
    "    trainset = data.build_full_trainset()\n",
    "\n",
    "    model = SVD(n_factors=n_factors, n_epochs=n_epochs, lr_all=lr_all, reg_all=reg_all)\n",
    "\n",
    "    # Entraîner le modèle\n",
    "    model.fit(trainset)\n",
    "\n",
    "    print(\"Début de la cross-validation\")\n",
    "\n",
    "    # Effectuer la validation croisée sur le Trainset\n",
    "    cv_results = cross_validate(model, data, measures=['RMSE', 'MAE'], cv=5, return_train_measures=True)\n",
    "\n",
    "    # Afficher les résultats\n",
    "    mean_rmse = cv_results['test_rmse'].mean()\n",
    "    print(\"Moyenne des RMSE :\", mean_rmse)\n",
    "\n",
    "    return model, mean_rmse, reader\n",
    "\n",
    "\n",
    "def save_model(model: SVD, filepath: str, version: str, reader: Reader) -> None:\n",
    "    \"\"\"Sauvegarde le modèle entraîné dans un fichier.\"\"\"\n",
    "    os.makedirs(os.path.dirname(filepath), exist_ok=True)\n",
    "\n",
    "    # Modifier le nom du fichier pour inclure la version\n",
    "    base, ext = os.path.splitext(filepath)\n",
    "    versioned_filepath = f\"{base}_{version}{ext}\"\n",
    "\n",
    "    # Sauvegarder le modèle et le contexte (reader)\n",
    "    with open(versioned_filepath, 'wb') as file:\n",
    "        pickle.dump({'model': model, 'reader': reader}, file)\n",
    "        print(f'Modèle sauvegardé sous {versioned_filepath}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ratings chargé\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userid</th>\n",
       "      <th>movieid</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>bayesian_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1112486027</td>\n",
       "      <td>3.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1112484676</td>\n",
       "      <td>3.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1112484819</td>\n",
       "      <td>3.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1112484727</td>\n",
       "      <td>4.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1112484580</td>\n",
       "      <td>4.32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userid  movieid  rating   timestamp  bayesian_mean\n",
       "0       1        2     3.5  1112486027           3.21\n",
       "1       1       29     3.5  1112484676           3.89\n",
       "2       1       32     3.5  1112484819           3.89\n",
       "3       1       47     3.5  1112484727           4.04\n",
       "4       1       50     3.5  1112484580           4.32"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = read_ratings('processed_ratings.csv')\n",
    "\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Début de la cross-validation\n",
      "Moyenne des RMSE : 0.7845606211457105\n"
     ]
    }
   ],
   "source": [
    "svd, mean_rmse, reader = train_model(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle sauvegardé sous /home/antoine/PROJET_MLOPS_RECO_MOVIES/data/models/svd_model_v1.pkl\n"
     ]
    }
   ],
   "source": [
    "save_model(svd, '/home/antoine/PROJET_MLOPS_RECO_MOVIES/data/models/svd_model.pkl', 'v1', reader=reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(filepath: str, version: str):\n",
    "    \"\"\"Charge le modèle entraîné depuis un fichier.\"\"\"\n",
    "    base, ext = os.path.splitext(filepath)\n",
    "    versioned_filepath = f\"{base}_{version}{ext}\"\n",
    "\n",
    "    with open(versioned_filepath, 'rb') as file:\n",
    "        model_data = pickle.load(file)\n",
    "        model = model_data['model']\n",
    "        reader = model_data['reader']\n",
    "        print(f'Modèle chargé depuis {versioned_filepath}')\n",
    "        return model, reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from surprise import SVD, Dataset\n",
    "\n",
    "def recommend_movies(model: SVD, user_id: int, df: pd.DataFrame, top_n: int = 10) -> list:\n",
    "    \"\"\"\n",
    "    Recommande des films à un utilisateur en fonction de ses évaluations prédites.\n",
    "\n",
    "    :param model: Le modèle SVD entraîné.\n",
    "    :param user_id: L'ID de l'utilisateur pour lequel on veut des recommandations.\n",
    "    :param df: DataFrame contenant les données des films et les évaluations.\n",
    "    :param top_n: Le nombre de films à recommander.\n",
    "    :return: Une liste des top_n films recommandés.\n",
    "    \"\"\"\n",
    "    # 1. Obtenir la liste des films que l'utilisateur a déjà évalués\n",
    "    movies_already_rated = df[df['userid'] == user_id]['movieid'].unique()\n",
    "\n",
    "    # 2. Créer une liste de tous les films possibles\n",
    "    all_movie_ids = df['movieid'].unique()\n",
    "\n",
    "    # 3. Filtrer les films que l'utilisateur n'a pas encore évalués\n",
    "    movies_to_predict = [movie_id for movie_id in all_movie_ids if movie_id not in movies_already_rated]\n",
    "\n",
    "    # 4. Faire des prédictions pour chaque film non évalué\n",
    "    predictions = []\n",
    "    for movie_id in movies_to_predict:\n",
    "        predictions.append((movie_id, model.predict(user_id, movie_id).est))\n",
    "\n",
    "    # 5. Trier les prédictions par ordre décroissant d'évaluation prédite\n",
    "    predictions.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # 6. Retourner les top_n films\n",
    "    top_recommendations = [movie_id for movie_id, _ in predictions[:top_n]]\n",
    "    return top_recommendations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv('/home/antoine/PROJET_MLOPS_RECO_MOVIES/data/raw/silver/processed_movies.csv')\n",
    "movie_titles = dict(zip(movies[\"movieid\"], movies[\"title\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The War at Home\n",
      "Very Potter Musical, A\n",
      "Zero Motivation (Efes beyahasei enosh)\n",
      "Crooks in Clover (a.k.a. Monsieur Gangster) (Les tontons flingueurs)\n",
      "Welfare\n",
      "Tito and Me (Tito i ja)\n",
      "Matrix, The\n",
      "For Neda\n",
      "Rewind This!\n",
      "Look of Silence, The\n"
     ]
    }
   ],
   "source": [
    "\n",
    "result = recommend_movies(svd, 1, ratings)\n",
    "\n",
    "for movie_id in result:\n",
    "    print(movie_titles[movie_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Salt of the Earth\n",
      "Tito and Me (Tito i ja)\n",
      "Welfare\n",
      "Zero Motivation (Efes beyahasei enosh)\n",
      "Look of Silence, The\n",
      "Lake, A (Un lac)\n",
      "Dirties, The\n",
      "Shawshank Redemption, The\n",
      "Strangers in Good Company\n",
      "Crooks in Clover (a.k.a. Monsieur Gangster) (Les tontons flingueurs)\n"
     ]
    }
   ],
   "source": [
    "result2 = recommend_movies(svd, 501, ratings)\n",
    "\n",
    "for movie_id in result2:\n",
    "    print(movie_titles[movie_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reco_movies",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
