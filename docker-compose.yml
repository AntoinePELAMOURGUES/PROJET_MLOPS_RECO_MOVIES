services:
  ### MLFLOW -------------------
  # This container runs the postgresql database for mlflow.
  postgres-mlflow:
    image: postgres:13
    container_name: postgres_mlflow
    environment:
      POSTGRES_USER: mlflow
      POSTGRES_PASSWORD: mlflow
      POSTGRES_DB: mlflow
    volumes:
      - postgres-db-volume-mlflow:/var/lib/postgresql/data
    healthcheck:
      test: [ "CMD", "pg_isready", "-U", "mlflow" ]
      interval: 5s
      retries: 5
    restart: always
    networks:
      - backend
  # This container runs the artifact storage as an S3 server.
  s3-artifact-storage:
    image: minio/minio
    volumes:
      - ./mlflow-data:/data
    environment: &env-mlflow-s3
      MINIO_ROOT_USER: mlflow_access
      MINIO_ROOT_PASSWORD: mlflow_secret
    command: server /data --console-address ":9001"
    container_name: s3_storage
    ports:
      - 9000:9000
      - 9001:9001
    healthcheck:
      test: [ "CMD", "curl -I http://localhost:9000/minio/health/live" ]
      interval: 5s
      retries: 5
    restart: always
    networks:
      - backend
  # This container creates the "data" in the S3 server, in which mlflow will later store the artifacts.
  mlflow-init:
    image: minio/mc
    container_name: mlflow_init
    depends_on:
      - s3-artifact-storage
    environment:
      <<: *env-mlflow-s3
    entrypoint: >
      /bin/sh -c " /usr/bin/mc config host add myminio http://s3-artifact-storage:9000 $$MINIO_ROOT_USER $$MINIO_ROOT_PASSWORD; /usr/bin/mc mb myminio/data; /usr/bin/mc policy download myminio/data; exit 0; "
    networks:
      - backend
  # This container runs the webserver for mlflow.
  mlflow-webserver:
    build:
      context: ./mlflow
      dockerfile: Dockerfile
    container_name: mlflow_webserver
    ports:
      - 5000:5000
    environment:
      MLFLOW_S3_ENDPOINT_URL: http://s3-artifact-storage:9000
      MLFLOW_S3_IGNORE_TLS: "true"
      AWS_ACCESS_KEY_ID: "mlflow_access"
      AWS_SECRET_ACCESS_KEY: "mlflow_secret"
    command: mlflow server --backend-store-uri postgresql://mlflow:mlflow@postgres-mlflow/mlflow --artifacts-destination s3://data -h 0.0.0.0 -p 5000 --serve-artifacts
    depends_on:
      - postgres-mlflow
      - s3-artifact-storage
      - mlflow-init
    networks:
      - backend
    volumes:
      - ./ml/models/:/data/model


  ### FASTAPI --------------------
  fastapi:
    build:
      context: ./api
      dockerfile: Dockerfile
    env_file:
      - .env
    volumes:
      - ./ml/data/processed/:/app/raw
      - ./ml/models/:/app/model
    ports:
      - "8002:8000"
    restart: always
    networks:
      - backend
    container_name: fastapi

  ### STREAMLIT --------------------
  streamlit:
    build:
      context: ./streamlit
      dockerfile: Dockerfile
    ports:
      - "8501:8501"
    restart: always
    networks:
      - backend
    depends_on:
      - fastapi
    container_name: streamlit

  ### PROMETHEUS --------------------
  prometheus:
    image: prom/prometheus:latest
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
      - shared_prometheus:/var/log/prometheus # Volume pour logs Prometheus
    ports:
      - "9090:9090"
    container_name: prometheus
    networks:
      - backend

  ### GRAFANA --------------------
  grafana:
    image: grafana/grafana-enterprise
    restart: unless-stopped
    environment:
      - GF_SERVER_ROOT_URL=http://my.grafana.server/
      - GF_INSTALL_PLUGINS=grafana-clock-panel
      - GF_SECURITY_ALLOW_EMBEDDING=true
    ports:
      - "3000:3000"
    volumes:
      - grafana_data:/var/lib/grafana
    container_name: grafana
    networks:
      - backend

  ### NODE EXPORTER --------------------
  node-exporter:
    image: prom/node-exporter
    container_name: node_exporter
    restart: unless-stopped
    ports:
      - "9100:9100" # Expose le port pour Node Exporter
    networks:
      - backend


volumes:
  shared_prometheus:
  postgres-db-volume-mlflow:
  supabase-db:
  grafana_data:

networks:
  backend:
    name: backend
    external: true

